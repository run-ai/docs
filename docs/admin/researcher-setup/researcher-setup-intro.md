---
title: Researcher Setup Overview
---

Following is a step-by-step guide for getting a new Researcher up to speed with Run:ai and Kubernetes.

## Change of Paradigms: from Docker to Kubernetes 

As part of Run:ai, the organization is typically moving from Docker-based workflows to Kubernetes. This [document](docker-to-runai.md) is an attempt to help the Researcher with this paradigm shift. It explains the basic concepts and provides links for further information about the Run:ai CLI.

## Setup the Run:ai Command-Line Interface

Run:ai CLI needs to be installed on the Researcher's machine. This [document](cli-install.md) provides step by step instructions.

## Provide the Researcher with a GPU Quota

To submit workloads with Run:ai, the Researcher must be provided with a _Project_ that contains a GPU quota. Please see [Working with Projects](../admin-ui-setup/project-setup.md) document on how to create Projects and set a quota.

## Provide access to the Run:ai User Interface

See [Setting up users](../admin-ui-setup/admin-ui-users.md) for further information on how to provide access to users.  

## Schedule an Onboarding Session

It is highly recommended to schedule an onboarding session for Researchers with a Run:ai customer success professional. Run:ai can help with the above transition, but adding to that, we at Run:ai have also acquired a large body of knowledge on data science best practices which can help streamline the Researchers' work as well as save money for the organization. 


 
 
 